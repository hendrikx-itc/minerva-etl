#!/usr/bin/env python
# -*- coding: utf-8 -*-
import os
import sys
import argparse
import logging
from contextlib import closing
from functools import partial

import psycopg2.extras

from minerva import __version__ as version
from minerva.db import parse_db_url
from minerva.util.config import load_config, get_defaults, ConfigError
from minerva.util import first
from minerva.db.query import Table
from minerva.storage.trend.types_v4 import TrendStore

package_name = "minerva"
script_name = os.path.basename(__file__)
config_file = "{}.conf".format(script_name)


def main():
    config_file_path = os.path.join("/etc/minerva", config_file)

    parser = argparse.ArgumentParser(description="Edit partitions")

    parser.add_argument(
        "--version", action="version", version=version,
        help="display version information and exit")

    parser.add_argument(
        "trendstores", metavar="TRENDSTORES", type=int, nargs='+',
        help="ids of trendstores to migrate")

    parser.add_argument(
        "-c", "--configfile", dest="configfile",
        default=config_file_path, help="the path to the config file")

    parser.add_argument(
        "-v", "--verbose", action="store_true", default=False,
        help="verbose output")

    parser.add_argument(
        "--partition-size", dest="partition_size", default=None,
        help="new partition size for trendstore")

    parser.add_argument(
        "--drop-old-partitions", action="store_true", default=False,
        help="drop old partitions after migrating")

    parser.add_argument(
        "--force", action="store_true", default=False,
        help="force migrate even if there are no apparent changes")

    parser.add_argument(
        "--generate-configfile", dest="generate_configfile",
        action=GenerateConfigFileAction, nargs=0,
        help="generate base config file")

    root_logger = logging.getLogger("")
    handler = logging.StreamHandler(sys.stdout)
    root_logger.addHandler(handler)

    args = parser.parse_args()

    try:
        config = load_config(get_defaults(package_name, config_file),
                             args.configfile)
    except ConfigError as exc:
        logging.error("error loading configuration: {}".format(exc))
        return 1

    if args.verbose:
        root_logger.setLevel(logging.DEBUG)

        create_connection = partial(connect, config["db_uri"], root_logger)
    else:
        root_logger.setLevel(logging.INFO)

        create_connection = partial(connect, config["db_uri"])

    tables_query = (
        "SELECT table_name "
        "FROM trend.partition "
        "WHERE "
        "trendstore_id = %s "
        "ORDER BY data_start"
    )

    with closing(create_connection()) as conn:
        for trendstore_id in args.trendstores:
            with closing(conn.cursor()) as cursor:
                trendstore = TrendStore.get_by_id(cursor, trendstore_id)

                if trendstore is None:
                    logging.info("no trendstore with id {}".format(
                        trendstore_id))
                    continue

                change = False

                if args.partition_size:
                    if args.partition_size == 'auto':
                        new_partition_size = default_partition_size(
                            trendstore.granularity)
                    else:
                        try:
                            new_partition_size = int(args.partition_size)
                        except ValueError:
                            logging.error(
                                "{} is not a valid partition size".format(
                                    args.partition_size))
                            return

                if args.partition_size and new_partition_size != trendstore.partition_size:
                    trendstore.partition_size = new_partition_size
                    change = True

                if not change and not args.force:
                    logging.info(
                        "no changes required for trendstore {}".format(
                            trendstore
                        )
                    )
                    continue

                trendstore.save(cursor)
                conn.commit()

                tables_query_args = trendstore_id

                cursor.execute(tables_query, tables_query_args)

                table_names = map(first, cursor.fetchall())

            tables = [Table("trend", name) for name in table_names]

            for table in tables:
                timestamps_query = (
                    "SELECT timestamp "
                    "FROM {} "
                    "GROUP BY timestamp "
                    "ORDER BY timestamp"
                ).format(table.render())

                with closing(conn.cursor()) as cursor:
                    cursor.execute(timestamps_query)

                    timestamps = map(first, cursor.fetchall())

                for timestamp in timestamps:
                    with closing(conn.cursor()) as cursor:
                        sys.stdout.write(
                            "{} - {}... ".format(table.name, timestamp)
                        )
                        sys.stdout.flush()

                        retries = 5

                        while retries:
                            try:
                                record_count = migrate_chunk(
                                    trendstore_id, table.name, timestamp
                                )(cursor)
                            except psycopg2.IntegrityError:
                                sys.stdout.write(
                                    "failed: timestamp already exists\n"
                                )
                                sys.stdout.flush()
                                retries = 0
                            except psycopg2.DatabaseError as exc:
                                sys.stdout.write(
                                    "error: {}\n\nretrying...".format(exc)
                                )
                                sys.stdout.flush()
                                retries -= 1
                            else:
                                sys.stdout.write(
                                    "{} records\n".format(record_count)
                                )
                                sys.stdout.flush()
                                retries = 0

                    conn.commit()

                if args.drop_old_partitions:
                    with closing(conn.cursor()) as cursor:
                        query = "DROP TABLE {} CASCADE".format(table.render())

                        cursor.execute(query)

                    conn.commit()

                    logging.info("dropped table {}".format(table.render()))

    return 0


def migrate_chunk(trendstore_id, table_name, timestamp):
    query = (
        "SELECT trend.migrate_chunk(trendstore, %s, %s) "
        "FROM trend.trendstore "
        "WHERE id = %s"
    )
    args = table_name, timestamp, trendstore_id

    def f(cursor):
        cursor.execute(query, args)

        return first(cursor.fetchone())

    return f


def default_partition_size(granularity):
    if granularity.name == '300':
        return 3 * 3600
    elif granularity.name == '900':
        return 6 * 3600
    elif granularity.name == '1800':
        return 6 * 3600
    elif granularity.name == '3600':
        return 24 * 3600
    elif granularity.name == '86400' or granularity.name == 'day':
        return 24 * 3600 * 7
    elif granularity.name == '604800' or granularity.name == 'week':
        return 24 * 3600 * 7 * 4
    elif granularity.name == 'month':
        return 24 * 3600 * 7 * 24
    else:
        raise Exception("granularity {} not supported".format(
            granularity.name))


def connect(db_url, logger=None):
    scheme, user, password, host, port, database = parse_db_url(db_url)

    assert scheme == "postgresql", "Only PostgreSQL connections are supported"

    create_connection = partial(
        psycopg2.connect, database=database, user=user, password=password,
        host=host, port=port
    )

    if logger:
        conn = create_connection(
            connection_factory=psycopg2.extras.LoggingConnection
        )

        conn.initialize(logger)
    else:
        conn = create_connection()

    return conn


class GenerateConfigFileAction(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        sys.stdout.write(get_defaults(package_name, config_file))
        sys.exit(0)


if __name__ == "__main__":
    main()
